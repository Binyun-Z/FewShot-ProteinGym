{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from peft import PeftModel, PeftConfig, LoraConfig, get_peft_model\n",
    "from peft.utils.other import fsdp_auto_wrap_policy\n",
    "from transformers import EsmForMaskedLM, EsmTokenizer, EsmConfig\n",
    "from esm import Alphabet,FastaBatchedDataset,ProteinBertModel,pretrained,MSATransformer\n",
    "import os\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "import accelerate\n",
    "from accelerate import Accelerator\n",
    "\n",
    "from data_utils import Mutation_Set,split_data\n",
    "from stat_utils import spearman, compute_score, BT_loss, KLloss\n",
    "import gc\n",
    "import warnings\n",
    "import time\n",
    "import yaml\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, model_reg, trainloder, optimizer, tokenizer, lambda_reg):\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    total_loss = 0.\n",
    "\n",
    "    for step, data in enumerate(trainloder):\n",
    "        seq, mask = data[0], data[1]\n",
    "        wt, wt_mask = data[2], data[3]\n",
    "        pos = data[4]\n",
    "        golden_score = data[5]\n",
    "        score, logits = compute_score(model, seq, mask, wt, pos, tokenizer)\n",
    "        score = score.cuda()\n",
    "\n",
    "        l_BT = BT_loss(score, golden_score)\n",
    "\n",
    "        out_reg = model_reg(wt, wt_mask)\n",
    "        logits_reg = out_reg.logits\n",
    "        l_reg = KLloss(logits, logits_reg, seq, mask)\n",
    "\n",
    "        loss = l_BT + lambda_reg*l_reg\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, testloader, tokenizer, accelerator, istest=False):\n",
    "    model.eval()\n",
    "    seq_list = []\n",
    "    score_list = []\n",
    "    gscore_list = []\n",
    "    with torch.no_grad():\n",
    "        for step, data in enumerate(testloader):\n",
    "            seq, mask = data[0], data[1]\n",
    "            wt, wt_mask = data[2], data[3]\n",
    "            pos = data[4]\n",
    "            golden_score = data[5]\n",
    "            pid = data[6]\n",
    "            if istest:\n",
    "                pid = pid.cuda()\n",
    "                pid = accelerator.gather(pid)\n",
    "                for s in pid:\n",
    "                    seq_list.append(s.cpu())\n",
    "\n",
    "            score, logits = compute_score(model, seq, mask, wt, pos, tokenizer)\n",
    "\n",
    "            score = score.cuda()\n",
    "            score = accelerator.gather(score)\n",
    "            golden_score = accelerator.gather(golden_score)\n",
    "            score = np.asarray(score.cpu())\n",
    "            golden_score = np.asarray(golden_score.cpu())\n",
    "            score_list.extend(score)\n",
    "            gscore_list.extend(golden_score)\n",
    "    score_list = np.asarray(score_list)\n",
    "    gscore_list = np.asarray(gscore_list)\n",
    "    sr = spearman(score_list, gscore_list)\n",
    "\n",
    "    if istest:\n",
    "        seq_list = np.asarray(seq_list)\n",
    "\n",
    "        return sr, score_list, seq_list\n",
    "    else:\n",
    "        return sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    def __init__(self, config_file='../config/training_config.yaml',\n",
    "                 fold_spilt_type = 'fold_random_5',\n",
    "                 model_seed=1,\n",
    "                 model = 'ESM-1v',\n",
    "                 ):\n",
    "        self.config = config_file\n",
    "        self.fold_spilt_type = fold_spilt_type\n",
    "        self.model_seed = model_seed\n",
    "        self.model = model\n",
    "\n",
    "\n",
    "    def display_config(self):\n",
    "        print(f\"Config File: {self.config_file}\")\n",
    "        print(f\"fold_spilt_type: {self.fold_spilt_type}\")\n",
    "        print(f\"Model Seed: {self.model_seed}\")\n",
    "        print(f\"Model: {self.model}\")\n",
    "\n",
    "args = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in config\n",
    "with open(f'{args.config}', 'r', encoding='utf-8') as f:\n",
    "    config = yaml.load(f.read(), Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch_size = int(int(config['batch_size'])/int(config['gpu_number']))\n",
    "accelerator = Accelerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of EsmForMaskedLM were not initialized from the model checkpoint at facebook/esm1v_t33_650M_UR90S_1 and are newly initialized: ['esm.contact_head.regression.bias', 'esm.contact_head.regression.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of EsmForMaskedLM were not initialized from the model checkpoint at facebook/esm1v_t33_650M_UR90S_1 and are newly initialized: ['esm.contact_head.regression.bias', 'esm.contact_head.regression.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "### creat model\n",
    "if config['model'] == 'ESM-1v':\n",
    "    basemodel = EsmForMaskedLM.from_pretrained(f'facebook/esm1v_t33_650M_UR90S_{args.model_seed}')\n",
    "    model_reg = EsmForMaskedLM.from_pretrained(f'facebook/esm1v_t33_650M_UR90S_{args.model_seed}')\n",
    "    tokenizer = EsmTokenizer.from_pretrained(f'facebook/esm1v_t33_650M_UR90S_{args.model_seed}')\n",
    "\n",
    "elif config['model'] == 'ESM-2':\n",
    "    basemodel = EsmForMaskedLM.from_pretrained('facebook/esm2_t48_15B_UR50D')\n",
    "    model_reg = EsmForMaskedLM.from_pretrained('facebook/esm2_t48_15B_UR50D')\n",
    "    tokenizer = EsmTokenizer.from_pretrained('facebook/esm2_t48_15B_UR50D')\n",
    "\n",
    "elif config['model'] == 'ESM-1b':\n",
    "    basemodel = EsmForMaskedLM.from_pretrained('facebook/esm1b_t33_650M_UR50S')\n",
    "    model_reg = EsmForMaskedLM.from_pretrained('facebook/esm1b_t33_650M_UR50S')\n",
    "    tokenizer = EsmTokenizer.from_pretrained('facebook/esm1b_t33_650M_UR50S')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pm in model_reg.parameters():\n",
    "    pm.requires_grad = False\n",
    "model_reg.eval()    #regularization model\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    r=int(config['lora_r']),\n",
    "    lora_alpha=int(config['lora_alpha']),\n",
    "    lora_dropout=float(config['lora_dropout']),\n",
    "    target_modules=[\"query\", \"value\"]\n",
    ")\n",
    "\n",
    "model = get_peft_model(basemodel, peft_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create optimizer and scheduler\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=float(config['ini_lr']))\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=2*int(config['max_epochs']), eta_min=float(config['min_lr']))\n",
    "if os.environ.get(\"ACCELERATE_USE_FSDP\", None) is not None:\n",
    "    accelerator.state.fsdp_plugin.auto_wrap_policy = fsdp_auto_wrap_policy(model)\n",
    "model, optimizer, scheduler = accelerator.prepare(model, optimizer, scheduler)\n",
    "model_reg = accelerator.prepare(model_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================preparing data=============\n",
      "==============data preparing done!================\n"
     ]
    }
   ],
   "source": [
    "# 执行五折交叉验证\n",
    "# for fold_i in range (1):\n",
    "accelerator.print(f'===================preparing data=============')\n",
    "with accelerator.main_process_first():\n",
    "    #数据加载: 确保数据集在主进程中加载完毕后，其他进程才能开始工作。\n",
    "    # train_csv = pd.DataFrame(None)\n",
    "    # for i in range(5):\n",
    "    #     if i == fold_i:\n",
    "    #         val_csv = pd.read_csv(f'../data/split_data/{args.fold_spilt_type}/data_{i}.csv')   #using 1/5 train data as validation set\n",
    "    #         test_csv = val_csv\n",
    "    #     temp_csv = pd.read_csv(f'../data/split_data/{args.fold_spilt_type}/data_{i}.csv')\n",
    "    #     train_csv = pd.concat([train_csv, temp_csv], axis=0)\n",
    "    train_csv = pd.read_csv(f'../data/split_data/{args.fold_spilt_type}/data_0.csv')\n",
    "    test_csv = pd.read_csv(f'../data/split_data/{args.fold_spilt_type}/data_1.csv')\n",
    "    val_csv = pd.read_csv(f'../data/split_data/{args.fold_spilt_type}/data_2.csv')\n",
    "\n",
    "\n",
    "#creat dataset and dataloader\n",
    "trainset = Mutation_Set(data=train_csv, tokenizer=tokenizer)\n",
    "testset = Mutation_Set(data=test_csv,  tokenizer=tokenizer)\n",
    "valset = Mutation_Set(data=val_csv,  tokenizer=tokenizer)\n",
    "with accelerator.main_process_first():\n",
    "    #数据加载: 确保数据集在主进程中加载完毕后，其他进程才能开始工作。\n",
    "    trainloader = DataLoader(trainset, batch_size=batch_size, collate_fn=trainset.collate_fn, shuffle=True,num_workers=64)\n",
    "    testloader = DataLoader(testset, batch_size=2, collate_fn=testset.collate_fn,num_workers=64)\n",
    "    valloader = DataLoader(valset, batch_size=2, collate_fn=testset.collate_fn,num_workers=64)\n",
    "\n",
    "trainloader = accelerator.prepare(trainloader)\n",
    "testloader = accelerator.prepare(testloader)\n",
    "valloader = accelerator.prepare(valloader)\n",
    "accelerator.print('==============data preparing done!================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([43], device='cuda:0'), tensor([29], device='cuda:0')]\n"
     ]
    }
   ],
   "source": [
    "for step, data in enumerate(trainloader):\n",
    "    seq, mask = data[0], data[1]\n",
    "    wt, wt_mask = data[2], data[3]\n",
    "    pos = data[4]\n",
    "    golden_score = data[5]\n",
    "    print(pos)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [0,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# for epoch in range(int(config['max_epochs'])):\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m----> 7\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_reg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlambda_reg\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     accelerator\u001b[38;5;241m.\u001b[39mprint(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m========epoch\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m; training loss :\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m=================\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      9\u001b[0m     sr \u001b[38;5;241m=\u001b[39m evaluate(model, valloader, tokenizer, accelerator)\n",
      "Cell \u001b[0;32mIn[8], line 12\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, model_reg, trainloder, optimizer, tokenizer, lambda_reg)\u001b[0m\n\u001b[1;32m     10\u001b[0m pos \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;241m4\u001b[39m]\n\u001b[1;32m     11\u001b[0m golden_score \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;241m5\u001b[39m]\n\u001b[0;32m---> 12\u001b[0m score, logits \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m score \u001b[38;5;241m=\u001b[39m score\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[1;32m     15\u001b[0m l_BT \u001b[38;5;241m=\u001b[39m BT_loss(score, golden_score)\n",
      "File \u001b[0;32m~/Project/ConFit-proteinGym/scripts/stat_utils.py:40\u001b[0m, in \u001b[0;36mcompute_score\u001b[0;34m(model, seq, mask, wt, pos, tokenizer)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(batch_size):\n\u001b[1;32m     39\u001b[0m     mut_pos \u001b[38;5;241m=\u001b[39m pos[i]\n\u001b[0;32m---> 40\u001b[0m     \u001b[43mmask_seq\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmut_pos\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m m_id\n\u001b[1;32m     42\u001b[0m out \u001b[38;5;241m=\u001b[39m model(mask_seq, mask, output_hidden_states\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     43\u001b[0m logits \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mlogits\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "best_sr = -np.inf\n",
    "endure = 0\n",
    "best_epoch = 0\n",
    "\n",
    "# for epoch in range(int(config['max_epochs'])):\n",
    "for epoch in range(1):\n",
    "    loss = train(model, model_reg, trainloader, optimizer, tokenizer, float(config['lambda_reg']))\n",
    "    accelerator.print(f'========epoch{epoch}; training loss :{loss}=================')\n",
    "    sr = evaluate(model, valloader, tokenizer, accelerator)\n",
    "    accelerator.print(f'========epoch{epoch}; val spearman correlation :{sr}=================')\n",
    "    scheduler.step()\n",
    "    if best_sr > sr:\n",
    "        endure += 1\n",
    "    else:\n",
    "        endure = 0\n",
    "        best_sr = sr\n",
    "        best_epoch = epoch\n",
    "\n",
    "        if not os.path.isdir(f'checkpoint/{args.fold_spilt_type}_best_epoch_{best_epoch}'):\n",
    "            if accelerator.is_main_process:\n",
    "                os.makedirs(f'checkpoint/{args.fold_spilt_type}_best_epoch_{best_epoch}')\n",
    "        save_path = os.path.join('checkpoint', f'{args.fold_spilt_type}_best_epoch_{best_epoch}',\n",
    "                                    f'seed{args.model_seed}')\n",
    "        accelerator.wait_for_everyone()\n",
    "        unwrapped_model = accelerator.unwrap_model(model)\n",
    "        unwrapped_model.save_pretrained(save_path)\n",
    "    if sr == 1.0:\n",
    "        accelerator.print(f'========early stop at epoch{epoch}!============')\n",
    "        break\n",
    "    if endure > int(config['endure_time']):\n",
    "        accelerator.print(f'========early stop at epoch{epoch}!============')\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # inference on the test sest\n",
    "# accelerator.print('=======training done!, test the performance!========')\n",
    "# save_path = Path(os.path.join('checkpoint', f''{args.fold_spilt_type}_best_epoch_{best_epoch}', f'seed{args.model_seed}'))\n",
    "# del basemodel\n",
    "# del model\n",
    "# accelerator.free_memory()\n",
    "\n",
    "# if config['model'] == 'ESM-1v':\n",
    "#     basemodel = EsmForMaskedLM.from_pretrained(f'facebook/esm1v_t33_650M_UR90S_{args.model_seed}')\n",
    "#     tokenizer = EsmTokenizer.from_pretrained(f'facebook/esm1v_t33_650M_UR90S_{args.model_seed}')\n",
    "\n",
    "# if config['model'] == 'ESM-2':\n",
    "#     basemodel = EsmForMaskedLM.from_pretrained('facebook/esm2_t48_15B_UR50D')\n",
    "#     tokenizer = EsmTokenizer.from_pretrained('facebook/esm2_t48_15B_UR50D')\n",
    "\n",
    "# if config['model'] == 'ESM-1b':\n",
    "#     basemodel = EsmForMaskedLM.from_pretrained('facebook/esm1b_t33_650M_UR50S')\n",
    "#     tokenizer = EsmTokenizer.from_pretrained('facebook/esm1b_t33_650M_UR50S')\n",
    "\n",
    "# model = PeftModel.from_pretrained(basemodel, save_path)\n",
    "# model = accelerator.prepare(model)\n",
    "# sr, score, pid = evaluate(model, testloader, tokenizer, accelerator, istest=True)\n",
    "# pred_csv = pd.DataFrame({f'{args.model_seed}': score, 'PID': pid})\n",
    "# if accelerator.is_main_process:\n",
    "#     if not os.path.isdir(f'predicted/'{args.fold_spilt_type}_best_epoch_{best_epoch}'):\n",
    "#         os.makedirs(f'predicted/'{args.fold_spilt_type}_best_epoch_{best_epoch}')\n",
    "#     if os.path.exists(f'predicted/'{args.fold_spilt_type}_best_epoch_{best_epoch}'/pred.csv'):\n",
    "#         pred = pd.read_csv(f'predicted/'{args.fold_spilt_type}_best_epoch_{best_epoch}'/pred.csv', index_col=0)\n",
    "#         pred = pd.merge(pred, pred_csv, on='PID')\n",
    "#     else:\n",
    "#         pred = pred_csv\n",
    "#     pred.to_csv(f'predicted/{dataset}/pred.csv')\n",
    "# accelerator.print(f'=============the test spearman correlation for early stop: {sr}==================')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "esm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
